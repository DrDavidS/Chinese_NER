{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import argparse\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _get_parser(args=[]):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train_path', type=str, default='D:\\自我学习\\天池比赛\\hy_round1_train_20200102', help='Directory of train file.')\n",
    "    parser.add_argument('--test_path', type=str, default='D:\\自我学习\\天池比赛\\hy_round1_testA_20200102', help='Directory of test file.')\n",
    "    parser.add_argument('--max_size', type=int, default=3969, help='number of a ship record.')\n",
    "#     parser.add_argument('--stop_words', type=str, default='./data/stop_words', help='Directory of stop words.')\n",
    "#     parser.add_argument('--sample_number', type=int, default=5, choices=[Range(1)], help='Sample number for each bucket.')\n",
    "#     parser.add_argument('--threshold', type=float, default=0.3, choices=[Range(0.0, 1.0)], help='Threshold for matching.')\n",
    "#     parser.add_argument('--name_len', type=int, default=9, choices=[Range(2)], help='Filename length.')\n",
    "#     parser.add_argument('--name_len_update', type=bool, default=False, help='To update file name length.')\n",
    "#     parser.add_argument('--lang', type=str, choices=['cn', 'en'], default='cn', help='Segmentor language setting.')\n",
    "    args = parser.parse_args(args=[])\n",
    "    return args\n",
    "args = _get_parser(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.train_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                              | 34/7000 [00:00<00:20, 337.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 7000/7000 [00:19<00:00, 355.23it/s]\n"
     ]
    }
   ],
   "source": [
    "#导入数据\n",
    "train_files = os.listdir(args.train_path)\n",
    "test_files = os.listdir(args.test_path)\n",
    "print(len(train_files), len(test_files))\n",
    "\n",
    "#将多个Dataframe拼接成一个，速度超级快\n",
    "ret = []\n",
    "train_labels = []\n",
    "for file in tqdm(train_files):\n",
    "    df = pd.read_csv(f'{args.train_path}/{file}')\n",
    "    train_labels.append(df['type'][0])\n",
    "    ret.append(df)\n",
    "df_train = pd.concat(ret)\n",
    "df_train.columns = ['ship','x','y','v','d','time','type']\n",
    "#删除无用的两列\n",
    "del df_train['time']\n",
    "del df_train['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:04<00:00, 401.81it/s]\n"
     ]
    }
   ],
   "source": [
    "#得到测试数据\n",
    "ret = []\n",
    "for file in tqdm(test_files):\n",
    "    df = pd.read_csv(f'{args.test_path}/{file}')\n",
    "    ret.append(df)\n",
    "df_test = pd.concat(ret)\n",
    "df_test.columns = ['ship','x','y','v','d','time']\n",
    "#删除无用的time\n",
    "del df_test['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>v</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.152038e+06</td>\n",
       "      <td>5.124873e+06</td>\n",
       "      <td>2.59</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.151230e+06</td>\n",
       "      <td>5.125218e+06</td>\n",
       "      <td>2.70</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.150421e+06</td>\n",
       "      <td>5.125563e+06</td>\n",
       "      <td>2.70</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.149612e+06</td>\n",
       "      <td>5.125907e+06</td>\n",
       "      <td>3.29</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.148803e+06</td>\n",
       "      <td>5.126252e+06</td>\n",
       "      <td>3.18</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              x             y     v    d\n",
       "0  6.152038e+06  5.124873e+06  2.59  102\n",
       "1  6.151230e+06  5.125218e+06  2.70  113\n",
       "2  6.150421e+06  5.125563e+06  2.70  116\n",
       "3  6.149612e+06  5.125907e+06  3.29   95\n",
       "4  6.148803e+06  5.126252e+06  3.18  108"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_ = df_train.drop(['ship'], axis=1)\n",
    "df_train_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2699638, 4)\n",
      "(782378, 4)\n"
     ]
    }
   ],
   "source": [
    "# df_train.shape\n",
    "#做归一化\n",
    "std = MinMaxScaler(feature_range=(0, 1))\n",
    "df_train_ = df_train.drop(['ship'], axis=1)\n",
    "scaled_train = std.fit_transform(df_train_)\n",
    "print(scaled_train.shape)\n",
    "\n",
    "df_test_ = df_test.drop(['ship'], axis=1)\n",
    "scaled_test = std.fit_transform(df_test_)\n",
    "print(scaled_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3  ship\n",
      "0  0.997602  0.740036  0.001211  0.000000  7000\n",
      "1  0.997647  0.740039  0.003523  0.961111  7000\n",
      "2  0.997651  0.740006  0.001211  0.000000  7000\n",
      "3  0.997651  0.740006  0.001211  0.197222  7000\n",
      "4  0.997651  0.740006  0.001211  0.083333  7000\n"
     ]
    }
   ],
   "source": [
    "#将ship序号重新放入到数据中\n",
    "scaled_train_df = pd.DataFrame(scaled_train)\n",
    "scaled_train_df['ship'] = np.array(df_train['ship'])\n",
    "# scaled_train_df.head()\n",
    "\n",
    "scaled_test_df = pd.DataFrame(scaled_test)\n",
    "scaled_test_df['ship'] = np.array(df_test['ship'])\n",
    "print(scaled_test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#换个列名\n",
    "scaled_train_df.columns = ['x','y','v','d','ship']\n",
    "scaled_test_df.columns = ['x','y','v','d','ship']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看每艘船的采集点数\n",
    "num_point_ship = pd.DataFrame(df_train['ship'].value_counts())\n",
    "num_point_ship = num_point_ship.reset_index(drop=False)\n",
    "num_point_ship.columns = ['ship','num_point']\n",
    "num_point_ship.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_point_ship.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_point_ship[num_point_ship['num_point']>500].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#求采集点数的众数和平均数\n",
    "#众数\n",
    "counts = np.bincount(np.array(num_point_ship['num_point']))\n",
    "zs = np.argmax(counts)\n",
    "print('众数: ',zs)\n",
    "\n",
    "print('平均数: ',num_point_ship['num_point'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['ship']==254]['type'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [254,0,0,0,0,0,'刺网']*10\n",
    "b = pd.DataFrame(np.array(a).reshape([-1,7]))\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7000*3969"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先按照最大的进行取padding,将每一艘船的采集点数都padding到相同的数，该数为最大的一个\n",
    "def convert_ship_to_same(df,limit_size = args.max_size):\n",
    "    all_ = []\n",
    "    ship_codes = df['ship'].unique()\n",
    "    if 'type' in df.columns:\n",
    "        del df['type']\n",
    "    for ship_code in tqdm(ship_codes):\n",
    "        temp = df[df['ship']==ship_code].copy()\n",
    "        #pad\n",
    "        if temp.shape[0] < limit_size:\n",
    "            rest_num = limit_size - temp.shape[0]\n",
    "            a = [0,0,0,0,ship_code]*rest_num\n",
    "            pad_ = pd.DataFrame(np.array(a).reshape([-1,5]))\n",
    "            pad_.columns = ['x','y','v','d','ship']\n",
    "            temp_ = pd.concat([temp,pad_],axis=0)\n",
    "            #print(temp_.shape)\n",
    "       #Trunc\n",
    "        else:\n",
    "            temp_ = temp[:limit_size]\n",
    "        all_.append(temp_.values)\n",
    "    all_data = np.array(all_)\n",
    "    print(all_data.shape)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 7000/7000 [00:47<00:00, 148.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 3969, 5)\n"
     ]
    }
   ],
   "source": [
    "df_train_pad = convert_ship_to_same(scaled_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:07<00:00, 267.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 3969, 5)\n"
     ]
    }
   ],
   "source": [
    "df_test_pad = convert_ship_to_same(scaled_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除ship的序号\n",
    "def delete_ship(df_arr):\n",
    "    a = []\n",
    "    for i in tqdm(range(len(df_arr))):\n",
    "        b = np.delete(df_arr[i], [4], axis=1) \n",
    "        a.append(b)\n",
    "    end = np.array(a)\n",
    "    print(end.shape)\n",
    "    return end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 7000/7000 [00:00<00:00, 10182.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 10610.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 3969, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 3969, 4)\n"
     ]
    }
   ],
   "source": [
    "train_input = delete_ship(df_train_pad)\n",
    "test_input = delete_ship(df_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#保存好输入\n",
    "import pickle\n",
    "\n",
    "with open('train_input.pkl', 'wb') as file:\n",
    "    pickle.dump(train_input, file)\n",
    "\n",
    "with open('test_input.pkl', 'wb') as file:\n",
    "    pickle.dump(test_input, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000,)\n",
      "[0 0 0 0 1 0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "#将标签转化成数字类别\n",
    "dict_label = {'拖网':0,'围网':1,'刺网':2}\n",
    "label = []\n",
    "for i in train_labels:\n",
    "    a = dict_label[i]\n",
    "    label.append(a)\n",
    "y = np.array(label)\n",
    "print(y.shape)\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y = np.reshape(y,newshape=[7000,-1])\n",
    "y_new = enc.fit_transform(y)\n",
    "y_new = y_new.toarray()\n",
    "print(y_new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Activation, MaxPool2D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5250, 3969, 4)\n",
      "(1750, 3969, 4)\n",
      "(5250, 3)\n",
      "(1750, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test, y_train, y_test  = train_test_split(train_input,y_new,test_size=0.25, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5250, 3969, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape([5250, 3969, 4,-1])\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape([1750, 3969, 4,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ==========~~~~~~~~=======\n",
      "Train on 4200 samples, validate on 1050 samples\n",
      "Epoch 1/15\n",
      "4200/4200 [==============================] - 302s 72ms/step - loss: 0.8854 - acc: 0.6181 - val_loss: 0.8426 - val_acc: 0.6229\n",
      "Epoch 2/15\n",
      "4200/4200 [==============================] - 302s 72ms/step - loss: 0.7731 - acc: 0.6507 - val_loss: 0.7411 - val_acc: 0.6714\n",
      "Epoch 3/15\n",
      "4200/4200 [==============================] - 303s 72ms/step - loss: 0.6984 - acc: 0.6845 - val_loss: 0.6511 - val_acc: 0.7276\n",
      "Epoch 4/15\n",
      "4200/4200 [==============================] - 303s 72ms/step - loss: 0.6138 - acc: 0.7274 - val_loss: 0.5980 - val_acc: 0.7267\n",
      "Epoch 5/15\n",
      "3392/4200 [=======================>......] - ETA: 54s - loss: 0.5809 - acc: 0.7376"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-59af2930038f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"training ==========~~~~~~~~=======\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 全部训练次数epochs=1次，每次训练批次大小batch_size=64\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Testing ==========~~~~~~~~~~~~======\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\anaconda_install\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\anaconda\\anaconda_install\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1712\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\anaconda\\anaconda_install\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1221\u001b[0m                             \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1223\u001b[1;33m                             \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1224\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1225\u001b[0m                         raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[1;32mC:\\anaconda\\anaconda_install\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_slice_arrays\u001b[1;34m(arrays, start, stop)\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\anaconda_install\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 初始化一个模型\n",
    "model = Sequential()\n",
    "\n",
    "# 模型卷积层设计\n",
    "model.add(Conv2D(\n",
    "    nb_filter=128,  # 第一层设置32个滤波器\n",
    "    nb_row=5,\n",
    "    nb_col=5,  # 设置滤波器的大小为5*5\n",
    "    padding='same',  # 选择滤波器的扫描方式，即是否考虑边缘\n",
    "    input_shape=(3969, 4,1)  # 设置输入的形状\n",
    "))\n",
    "\n",
    "# 选择激活函数\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 设置下采样(池化层）\n",
    "model.add(MaxPool2D(\n",
    "    pool_size=(2,2),  # 下采样格为2*2\n",
    "    strides=(2,2),  # 向右向下的步长\n",
    "    padding='same', # padding mode is 'same'\n",
    "))\n",
    "\n",
    "model.add(Conv2D(64, (5, 5), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(strides=(2, 2), padding='same'))\n",
    "\n",
    "\n",
    "# 使用Flatten函数，将输入数据扁平化（因为输入数据是一个多维的形式，需要将其扁平化）\n",
    "model.add(Flatten())  # 将多维的输入一维化\n",
    "model.add(Dense(128))  # 全连接层1024个点\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 在建设一层\n",
    "model.add(Dense(3))  # 输入是个类别\n",
    "model.add(Activation('softmax'))  # 用于分类的softmax函数\n",
    "\n",
    "adam = Adam()  # 学习速率lr=0.0001\n",
    "\n",
    "model.compile(optimizer=adam,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "print(\"training ==========~~~~~~~~=======\")\n",
    "model.fit(X_train, y_train,validation_split=0.2,epochs=15, batch_size=64,verbose=1)  # 全部训练次数epochs=1次，每次训练批次大小batch_size=64\n",
    "\n",
    "print(\"Testing ==========~~~~~~~~~~~~======\")\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"\\nloss:\", loss)\n",
    "print(\"\\nTest:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = test_input.reshape([test_input.shape[0],test_input.shape[1],test_input.shape[2],-1])\n",
    "results = model.predict(test_input)\n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index = np.array([np.argmax(x) for x in results])\n",
    "label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_index = df_test['ship'].unique()\n",
    "\n",
    "label_index = label_index.reshape([len(label_index),-1])\n",
    "ship_index = ship_index.reshape([len(ship_index),-1])\n",
    "ss = pd.DataFrame(np.concatenate([ship_index,label_index],axis=1))\n",
    "ss.columns = ['ship','label']\n",
    "print(ss.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_label = {0:'拖网', 1:'围网', 2:'刺网'}\n",
    "ss['y'] = ss['label'].map(reverse_label)\n",
    "print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ss.to_csv('sub_2_0110.csv',index=False,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
